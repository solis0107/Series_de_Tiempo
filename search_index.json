[["requerimientos.html", "Capítulo 2 Requerimientos 2.1 Instalación de librerias 2.2 Importe de los datos 2.3 Formato", " Capítulo 2 Requerimientos En este apartado se detallará el importe y preparación de los datos utilizados al igual que las librerías que se requieren instalar para el desarrollo de este libro. 2.1 Instalación de librerias install.packages(&quot;Rcpp&quot;) ## The following package(s) will be installed: ## ## - Rcpp [1.0.11] ## ## These packages will be installed into &quot;C:/Users/JSOLISP/OneDrive - TCC/Escritorio/PERSN/Universidad/Series_de_tiempo/PROYECTO_BOOKDOWN/renv/library/R-4.3/x86_64-w64-mingw32&quot;. ## ## # Installing packages -------------------------------------------------------- ## ## - Installing Rcpp ... OK [linked from cache in 0.0013s] ## ## Successfully installed 1 package in 16 milliseconds. install.packages(&quot;rlang&quot;) ## The following package(s) will be installed: ## ## - rlang [1.1.1] ## ## These packages will be installed into &quot;C:/Users/JSOLISP/OneDrive - TCC/Escritorio/PERSN/Universidad/Series_de_tiempo/PROYECTO_BOOKDOWN/renv/library/R-4.3/x86_64-w64-mingw32&quot;. ## ## # Installing packages -------------------------------------------------------- ## ## - Installing rlang ... OK [linked from cache in 0.0023s] ## ## Successfully installed 1 package in 18 milliseconds. install.packages(&quot;readxl&quot;) ## The following package(s) will be installed: ## ## - readxl [1.4.3] ## ## These packages will be installed into &quot;C:/Users/JSOLISP/OneDrive - TCC/Escritorio/PERSN/Universidad/Series_de_tiempo/PROYECTO_BOOKDOWN/renv/library/R-4.3/x86_64-w64-mingw32&quot;. ## ## # Installing packages -------------------------------------------------------- ## ## - Installing readxl ... OK [linked from cache in 0.0013s] ## ## Successfully installed 1 package in 15 milliseconds. install.packages(&quot;forecast&quot;) ## The following package(s) will be installed: ## ## - forecast [8.21.1] ## ## These packages will be installed into &quot;C:/Users/JSOLISP/OneDrive - TCC/Escritorio/PERSN/Universidad/Series_de_tiempo/PROYECTO_BOOKDOWN/renv/library/R-4.3/x86_64-w64-mingw32&quot;. ## ## # Installing packages -------------------------------------------------------- ## ## - Installing forecast ... OK [linked from cache in 0.0012s] ## ## Successfully installed 1 package in 14 milliseconds. install.packages(&quot;tseries&quot;) ## The following package(s) will be installed: ## ## - tseries [0.10-54] ## ## These packages will be installed into &quot;C:/Users/JSOLISP/OneDrive - TCC/Escritorio/PERSN/Universidad/Series_de_tiempo/PROYECTO_BOOKDOWN/renv/library/R-4.3/x86_64-w64-mingw32&quot;. ## ## # Installing packages -------------------------------------------------------- ## ## - Installing tseries ... OK [linked from cache in 0.0014s] ## ## Successfully installed 1 package in 16 milliseconds. install.packages(&quot;trend&quot;) ## The following package(s) will be installed: ## ## - trend [1.1.5] ## ## These packages will be installed into &quot;C:/Users/JSOLISP/OneDrive - TCC/Escritorio/PERSN/Universidad/Series_de_tiempo/PROYECTO_BOOKDOWN/renv/library/R-4.3/x86_64-w64-mingw32&quot;. ## ## # Installing packages -------------------------------------------------------- ## ## - Installing trend ... OK [linked from cache in 0.0014s] ## ## Successfully installed 1 package in 16 milliseconds. install.packages(&quot;Kendall&quot;) ## The following package(s) will be installed: ## ## - Kendall [2.2.1] ## ## These packages will be installed into &quot;C:/Users/JSOLISP/OneDrive - TCC/Escritorio/PERSN/Universidad/Series_de_tiempo/PROYECTO_BOOKDOWN/renv/library/R-4.3/x86_64-w64-mingw32&quot;. ## ## # Installing packages -------------------------------------------------------- ## ## - Installing Kendall ... OK [linked from cache in 0.0015s] ## ## Successfully installed 1 package in 14 milliseconds. install.packages(&quot;ggplot2&quot;) ## The following package(s) will be installed: ## ## - ggplot2 [3.4.3] ## ## These packages will be installed into &quot;C:/Users/JSOLISP/OneDrive - TCC/Escritorio/PERSN/Universidad/Series_de_tiempo/PROYECTO_BOOKDOWN/renv/library/R-4.3/x86_64-w64-mingw32&quot;. ## ## # Installing packages -------------------------------------------------------- ## ## - Installing ggplot2 ... OK [linked from cache in 0.0012s] ## ## Successfully installed 1 package in 14 milliseconds. install.packages(&quot;ggfortify&quot;) ## The following package(s) will be installed: ## ## - ggfortify [0.4.16] ## ## These packages will be installed into &quot;C:/Users/JSOLISP/OneDrive - TCC/Escritorio/PERSN/Universidad/Series_de_tiempo/PROYECTO_BOOKDOWN/renv/library/R-4.3/x86_64-w64-mingw32&quot;. ## ## # Installing packages -------------------------------------------------------- ## ## - Installing ggfortify ... OK [linked from cache in 0.0012s] ## ## Successfully installed 1 package in 15 milliseconds. install.packages(&quot;lubridate&quot;) ## The following package(s) will be installed: ## ## - lubridate [1.9.2] ## ## These packages will be installed into &quot;C:/Users/JSOLISP/OneDrive - TCC/Escritorio/PERSN/Universidad/Series_de_tiempo/PROYECTO_BOOKDOWN/renv/library/R-4.3/x86_64-w64-mingw32&quot;. ## ## # Installing packages -------------------------------------------------------- ## ## - Installing lubridate ... OK [linked from cache in 0.0011s] ## ## Successfully installed 1 package in 14 milliseconds. install.packages(&quot;aTSA&quot;) ## The following package(s) will be installed: ## ## - aTSA [3.1.2] ## ## These packages will be installed into &quot;C:/Users/JSOLISP/OneDrive - TCC/Escritorio/PERSN/Universidad/Series_de_tiempo/PROYECTO_BOOKDOWN/renv/library/R-4.3/x86_64-w64-mingw32&quot;. ## ## # Installing packages -------------------------------------------------------- ## ## - Installing aTSA ... OK [linked from cache in 0.0012s] ## ## Successfully installed 1 package in 14 milliseconds. install.packages(&quot;RSNNS&quot;) ## The following package(s) will be installed: ## ## - RSNNS [0.4-16] ## ## These packages will be installed into &quot;C:/Users/JSOLISP/OneDrive - TCC/Escritorio/PERSN/Universidad/Series_de_tiempo/PROYECTO_BOOKDOWN/renv/library/R-4.3/x86_64-w64-mingw32&quot;. ## ## # Installing packages -------------------------------------------------------- ## ## - Installing RSNNS ... OK [linked from cache in 0.0013s] ## ## Successfully installed 1 package in 14 milliseconds. install.packages(&quot;quantmod&quot;) ## The following package(s) will be installed: ## ## - quantmod [0.4.25] ## ## These packages will be installed into &quot;C:/Users/JSOLISP/OneDrive - TCC/Escritorio/PERSN/Universidad/Series_de_tiempo/PROYECTO_BOOKDOWN/renv/library/R-4.3/x86_64-w64-mingw32&quot;. ## ## # Installing packages -------------------------------------------------------- ## ## - Installing quantmod ... OK [linked from cache in 0.0013s] ## ## Successfully installed 1 package in 14 milliseconds. 2.2 Importe de los datos library(readxl) ruta_archivo &lt;- &quot;datos.xlsx&quot; nombre_hoja &lt;- &quot;datos&quot; datos &lt;- read_excel(ruta_archivo, sheet = &#39;datos&#39;) 2.3 Formato Tipos de datos Originales: data_types &lt;- sapply(datos, class) print(data_types) ## Date Month Year Week day Volume ## &quot;character&quot; &quot;numeric&quot; &quot;numeric&quot; &quot;numeric&quot; &quot;numeric&quot; &quot;numeric&quot; Es requerido para el desarrollo que la serie de tiempo tenga el formato de fecha en tipo Date datos$Date &lt;- as.Date(datos$Date) Creación de la serie de tiempo: serie_tiempo &lt;- ts(datos$Volume, start = min(datos$Date), frequency = 7) "],["análisis-de-descriptivo-y-transformaciones.html", "Capítulo 3 Análisis de descriptivo y transformaciones 3.1 Visualización Inicial 3.2 Parametros de la seire de tiempo 3.3 Descomponsición de la serie 3.4 Analisis de Tendencia 3.5 Analisis de Estacionalidad 3.6 Análisis de estacionariedad 3.7 Tranformación (Diferenciación)", " Capítulo 3 Análisis de descriptivo y transformaciones 3.1 Visualización Inicial La serie de tiempo a analizar muestra el volumen de llamadas que ingresan diariamente en una linea telefónica; demos una primera visualización a la serie de tiempo que se analizará: library(ggplot2) ggplot(datos, aes(x = Date, y = Volume)) + geom_line() + labs(x = &quot;Fechas&quot;, y = &quot;Valores&quot;, title = &quot;Serie de Tiempo&quot;)+ scale_x_date(date_breaks = &quot;1 month&quot;, date_labels = &quot;%Y-%B&quot;)+ theme_minimal() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) De forma general podemos ver que la serie de tiempo muestra un comportamiento estacional, sin una clara tendencia. No se evidencian valores atípicos significativos, pero estos se validaran próximamente. 3.2 Parametros de la seire de tiempo Exploremos el tipo de dato y la ventana de tiempo en la que se presenta esta serie: min_date &lt;- min(datos$Date) max_date &lt;- max(datos$Date) tipo_dato &lt;- class(serie_tiempo) print(paste(&quot;Mínimo día:&quot;, min_date)) ## [1] &quot;Mínimo día: 2022-05-22&quot; print(paste(&quot;Máximo día:&quot;, max_date)) ## [1] &quot;Máximo día: 2023-04-09&quot; print(paste(&quot;Tipo de dato:&quot;, tipo_dato)) ## [1] &quot;Tipo de dato: ts&quot; Confirmamos que la serie de tiempo quedo en el formato correcto “ts” y que esta trae datos desde el 22 de mayo del 2022 hasta el 9 de abril del 2023. En este apartado haremos un análisis descriptivo de la serie de tiempo, exploraremos sus componentes y aplicaremos alguna transformación en caso de esta sea requerida. 3.3 Descomponsición de la serie Iniciemos descomponiendo la serie de tiempo de forma aditiva, dado que la amplitud de las estacionalidades se mantiene en el tiempo,no se considera la descomposición multiplicativa. library(ggplot2) library(ggfortify) # Descomposición de la serie de tiempo fit &lt;- decompose(serie_tiempo, type=&#39;additive&#39;) autoplot(fit)+ labs(title = &quot;Descomposición de la serie de tiempo&quot;, x = &quot;Tiempo&quot;, y = &quot;Valor&quot;, colour = &quot;Gears&quot;)+ theme_bw() ## Warning: Removed 12 rows containing missing values (`geom_line()`). De forma general podemos ver que no hay una clara tendencia, aunque por ventanas de tiempo si se logra mantener una tendencia al alza o a la baja. La serie presenta una fuerte estacionalidad, la cual es homogenea para todo el periodo analizado. Los residuos presentan un buen comportamiento, están centrados en cero y no tienen un patron marcado, se pueden considerar aleatorios. 3.4 Analisis de Tendencia Dado que la existencia de tendencia en la serie no es muy clara, se ejecutara el test Kendall para definir si existe o no tendencia en la serie analizada: Ho: La serie no tiene tendencia H1: La serie si presenta tendencia library(Kendall) mk_test &lt;- Kendall(y=datos$Volume, x =datos$Date ) summary(mk_test) ## Score = -5464 , Var(Score) = 3761233 ## denominator = 51884.36 ## tau = -0.105, 2-sided pvalue =0.0048495 A un nivel de significancia del 0.05 se concluye que hay evidencia suficiente para soportar que la serie si presenta tendencia. 3.5 Analisis de Estacionalidad La estacionalidad de esta serie es bastante clara, pero podemos tener mayor detalle de esta analizando las gráficas ACF y PACF. La gráfica de ACF y PACF muestran la correlación entre una serie de tiempo y sus valores rezagados, pero la gráfica PACF elimina la influencia de los rezagos intermedios. En otras palabras, muestra la correlación directa entre dos puntos en el tiempo después de eliminar la correlación indirecta a través de otros rezagos. par(mfrow = c(1, 2)) acf(serie_tiempo) pacf(serie_tiempo) Por la forma en que se presentan los rezagos en la gráfica ACF se puede evidenciar que si existe una un patrón en la serie de tiempo de de 7 tiempos. Esto tiene sentido dado que la periodicidad del proceso analizado es semanal. 3.6 Análisis de estacionariedad Una serie de tiempo se considera estacionaria cuando sus propiedades estadísticas se mantienen constantes a lo largo del tiempo, lo que significa que no muestra cambios sistemáticos en su media, varianza y autocorrelación a medida que avanza el tiempo. En términos más simples, una serie de tiempo estacionaria es una serie en la que los patrones y características se repiten de manera consistente en diferentes períodos. Se utilizara el test ADF para probar si existe estacionariedad en la serie estudiada: Ho: La serie es no estacionaria: tiene raíz unitaria H1: La serie es estacionaria: no tiene raíz unitaria library(tseries) ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo adf.test(serie_tiempo) ## ## Augmented Dickey-Fuller Test ## ## data: serie_tiempo ## Dickey-Fuller = -1.8044, Lag order = 6, p-value = 0.659 ## alternative hypothesis: stationary Con un nivel de significance de 0.05 se concluye que no hay evidencia sufifiencte para decir que la serie es estacionaria, esto resultado es coherente con el test de tendencia el cual mostró que la serie efectivamente si presenta una tendencia en el tiempo. 3.6.1 Análisis de rezagos El análisis de rezagos se utiliza para ver la correlación que existe entre los valores y el n valor rezagado; analicemos la relación que existe entre cada valor y sus primeros 8 rezagos, considero que los primeros 8 son suficiente dado que se esperaría ver una relación de los días de la semana entre sí, Osea lunes-lunes, martes-martes… etc. library(ggplot2) lag.plot(serie_tiempo,lags=8,layout=c(2,4)) La gráfica de ACF muestra la correlación entre una serie de tiempo y sus valores rezagados (anteriores) en diferentes intervalos de tiempo. Cada barra en la gráfica representa la correlación en un rezago específico. Como era de esperarse, se evidencia un patrón claro en el lag 7, esto significa que hay una alta correlación entre la serie y 7 rezagos. 3.7 Tranformación (Diferenciación) Dado que la serie presenta tendencia, se debe intentará quitar esta tendencia con el metodo de defierenciación. seriedf1 =diff(serie_tiempo,differences=1) Analicemos la serie transformada library(ggplot2) library(ggfortify) # Descomposición de la serie de tiempo fit &lt;- decompose(seriedf1, type=&#39;additive&#39;) autoplot(fit)+ labs(title = &quot;Descomposición de la serie de tiempo&quot;, x = &quot;Tiempo&quot;, y = &quot;Valor&quot;, colour = &quot;Gears&quot;)+ theme_bw() ## Warning: Removed 12 rows containing missing values (`geom_line()`). Efectivamente se redujo la tendencia en la serie de tiempo, sobre todo en los últimos meses de el expectro analizado, originalmente este tenia una tendencia a la baja y ahora se ve mucho mas suavizado. Confirmemos la no existencia de tendencia ejecutando nuevamente el test ADF Ho: La serie es no estacionaria: tiene raíz unitaria H1: La serie es estacionaria: no tiene raíz unitaria library(tseries) adf.test(seriedf1) ## Warning in adf.test(seriedf1): p-value smaller than printed p-value ## ## Augmented Dickey-Fuller Test ## ## data: seriedf1 ## Dickey-Fuller = -12.545, Lag order = 6, p-value = 0.01 ## alternative hypothesis: stationary A un nivel de significancia del 0.05 podemos concluir que hay evidencia suficiente para decir que la serie es estacionaria por lo que se confirma la eliminación de la tendencia. "],["modelado.html", "Capítulo 4 Modelado 4.1 Regresión Lineal 4.2 Suavisamiento Exponencial Simple 4.3 Suavisamiento Exponencial Triple (Holt-Winters) 4.4 Modelo ARIMA 4.5 Modelo PROHET 4.6 Modelo Redes Neuronales de Elman y Jordan", " Capítulo 4 Modelado 4.1 Regresión Lineal Analicemos el modelado de esta serie de tiempo con una regresión lineal; si bien, la regresión no va a ser util para modelar esta serie de tiempo, nos dará una vista general de la tendencia de los datos. plot(serie_tiempo) abline(reg = lm(serie_tiempo ~ time(serie_tiempo))) 4.2 Suavisamiento Exponencial Simple el suavisamiento exponencial es especialmente útil cuando se trabaja con datos que muestran tendencias y patrones suaves, pero no poseen patrones estacionales o cíclicos pronunciados. Dado que nuestra serie presenta una fuerte estacionalidad, no se espera que este método genere un buen ajuste a la serie. Analicemos su comportamiento: library(forecast) ## Registered S3 methods overwritten by &#39;forecast&#39;: ## method from ## autoplot.Arima ggfortify ## autoplot.acf ggfortify ## autoplot.ar ggfortify ## autoplot.bats ggfortify ## autoplot.decomposed.ts ggfortify ## autoplot.ets ggfortify ## autoplot.forecast ggfortify ## autoplot.stl ggfortify ## autoplot.ts ggfortify ## fitted.ar ggfortify ## fortify.ts ggfortify ## residuals.ar ggfortify fcast_ses &lt;- ses(serie_tiempo, h = 12) autoplot(fcast_ses) + autolayer(fitted(fcast_ses), series=&quot;Fitted&quot;) Como era de esperarse, el suavisamiento exponencial simple no logra seguir la fuerte estacionalidad que tiene la serie de tiempo. 4.3 Suavisamiento Exponencial Triple (Holt-Winters) A continuación analizaremos el comportamiento del modelado Hold-Winters en la serie de tiempo, como se habia provado anteriormente, esta serie tiene estacionalidad y tendencia, por lo que se espera tener buenos resultados con este modelo. mod1 = HoltWinters(serie_tiempo, seasonal = &quot;additive&quot;) plot(mod1) De forma general, se puede ver un buen ajuste del modelo a los datos, no solo en la tendencia que estos llevan sino también en la fuerte estacionalidad que tiene la serie de tiempo. El modelo es capaz de respetar tanto los 4.4 Modelo ARIMA Como lo hemos visto en el analisis descriptivo y en el modelado de regresión lineal, nuestra serie no es estacionaria, al intentar utilizar un modelo ARIMA se debe garantizar que la serie de tiempo es estacionaria. Para esto se realizará una transformación a la serie para lograr que esta sea estacionaria utilizando la función adf. library(aTSA) ## ## Attaching package: &#39;aTSA&#39; ## The following object is masked from &#39;package:forecast&#39;: ## ## forecast ## The following objects are masked from &#39;package:tseries&#39;: ## ## adf.test, kpss.test, pp.test ## The following object is masked from &#39;package:graphics&#39;: ## ## identify adf.test(diff(serie_tiempo)) ## Augmented Dickey-Fuller Test ## alternative: stationary ## ## Type 1: no drift no trend ## lag ADF p.value ## [1,] 0 -22.7 0.01 ## [2,] 1 -19.0 0.01 ## [3,] 2 -16.0 0.01 ## [4,] 3 -14.2 0.01 ## [5,] 4 -18.8 0.01 ## [6,] 5 -26.9 0.01 ## Type 2: with drift no trend ## lag ADF p.value ## [1,] 0 -22.7 0.01 ## [2,] 1 -19.0 0.01 ## [3,] 2 -16.0 0.01 ## [4,] 3 -14.2 0.01 ## [5,] 4 -18.8 0.01 ## [6,] 5 -26.9 0.01 ## Type 3: with drift and trend ## lag ADF p.value ## [1,] 0 -22.7 0.01 ## [2,] 1 -19.0 0.01 ## [3,] 2 -15.9 0.01 ## [4,] 3 -14.2 0.01 ## [5,] 4 -18.7 0.01 ## [6,] 5 -26.9 0.01 ## ---- ## Note: in fact, p.value = 0.01 means p.value &lt;= 0.01 Con este resultado confirmamos que la serie ya se encuentra estacionaria. Encontramos los parametros ARIMA de la serie de tiempo utilizando la funcion auto.arima modelo&lt;-auto.arima(diff(serie_tiempo), seasonal = FALSE) summary(modelo) ## Series: diff(serie_tiempo) ## ARIMA(3,0,2) with zero mean ## ## Coefficients: ## ar1 ar2 ar3 ma1 ma2 ## 0.8245 -0.4386 -0.2411 -1.5124 0.7799 ## s.e. 0.0690 0.0690 0.0623 0.0464 0.0477 ## ## sigma^2 = 3395: log likelihood = -1764.57 ## AIC=3541.14 AICc=3541.4 BIC=3563.78 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ## Training set -0.3987745 57.81435 46.44426 68.63847 210.5593 0.9619898 ## ACF1 ## Training set -0.04708994 Utilizando estos parametros para hacer predicciones en el modelo modelo_arima &lt;- arima(diff(serie_tiempo), order = c(3,0,2)) n_predicciones &lt;- 10 predicciones &lt;- predict(modelo_arima, n.ahead = n_predicciones) # Visualiza las predicciones plot(diff(serie_tiempo) , main = &quot;Serie Temporal y Predicciones&quot;) lines(predicciones$pred, col = &quot;red&quot;, lty = 2) # Línea de predicciones legend(&quot;topright&quot;, legend = &quot;Predicciones&quot;, col = &quot;red&quot;, lty = 2) Veamos el ajuste del modelo a la serie de tiempo: library(forecast) # Graficar la serie de tiempo original plot(diff(serie_tiempo), main = &quot;Serie Temporal vs. Modelo ARIMA&quot;) # Agregar las predicciones del modelo ARIMA al gráfico lines(fitted(modelo_arima), col = &quot;blue&quot;, lwd = 0.5) # Línea de predicciones La serie logra captar los patrones de estacionariedad, se confirma nuevamente que la serie quedo estacionaria, no se evidencian patrones de tendencia en el comportamiento de esta. Si bien aún no podemos definir que modelo se ajustó mejor porque no hemos definido medidas de desempeño, pero para la serie sin tendencia este parece tener un buen ajuste. 4.4.1 Analisis de residuales en modelo Arima Para que el modelo pueda ser utilizado se debe garantizar que este tiene ruido blanco, por lo que haremos verificaciones de normalidad, independencia y homocedasticidad y media cero en los errores. 4.4.1.1 Normalidad Ho: Los errores distribuyen normal H1: Los errores no distribuyen normal residuales&lt;-modelo_arima$residuals qqnorm(residuales) qqline(residuales) shapiro.test(residuales) ## ## Shapiro-Wilk normality test ## ## data: residuales ## W = 0.99528, p-value = 0.4369 Con un nivel de significancia de 0.05 no se puede concluir que los errores no siguen una distribución normal. Esto se reafirma en la grafica, la cual muestra un comportamiento muy señido a la linea de normalidad. 4.4.1.2 Homocedastidad y media cero acf(residuals(modelo_arima)) Del análisis visual que nos da gráfica, se puede concluir que los errores si están centrados en cero pero estos no tienen una varianza constante, por lo que existe heterocedastidad. 4.4.1.3 Independencia Ho: Los residuo son independientes H1: Los residuos son dependientes Box.test(residuales,type = &quot;Ljung-Box&quot;) ## ## Box-Ljung test ## ## data: residuales ## X-squared = 0.72194, df = 1, p-value = 0.3955 A un nivel de significancia de 0.05 no se puede concluir que los residuos no son independientes. Si bien la mayoria de los supuestos se cumplen, los residuos presentan heterosedasticisas, su varianza varia en el tiempo, por lo que no se puede decir que le modelo presenta ruido blanco. 4.5 Modelo PROHET Dado que nuesta serie de tiempo presenta una fuerte estacionalidad semanal y que la tendencia es un factor a considerar en ella, el algortimo prohet de facebook podría mostrar resultados interesantes. Analicemos el pronostico ajustando este algoritmo a la serie de tiempo: install.packages(&quot;prophet&quot;) ## The following package(s) will be installed: ## ## - prophet [1.0] ## ## These packages will be installed into &quot;C:/Users/JSOLISP/OneDrive - TCC/Escritorio/PERSN/Universidad/Series_de_tiempo/PROYECTO_BOOKDOWN/renv/library/R-4.3/x86_64-w64-mingw32&quot;. ## ## # Installing packages -------------------------------------------------------- ## ## - Installing prophet ... OK [linked from cache in 0.0013s] ## ## Successfully installed 1 package in 15 milliseconds. library(prophet) ## Loading required package: Rcpp ## Loading required package: rlang library(ggplot2) data &lt;- data.frame(ds = datos$Date, y = datos$Volume) # Crear un objeto Prophet model &lt;- prophet(data, daily.seasonality=TRUE, yearly.seasonality=FALSE) # Realizar las previsiones future &lt;- make_future_dataframe(model, periods = 4) # &quot;n&quot; es el número de períodos a predecir forecast &lt;- predict(model, future) # Visualizar los resultados plot(forecast) # Para ver la comparación entre los valores reales y las previsiones plot(model, forecast) De forma general podemos decir que el algoritmo no presenta muy buen ajuste a nuestra serie de tiempo. 4.6 Modelo Redes Neuronales de Elman y Jordan Apliquemos las redes neuronales de Elman y Jordan a nuestra serie de tiempo para analizar el comportamiento que esta tiene tsData = serie_tiempo print(tsData) ## Time Series: ## Start = c(19134, 1) ## End = c(19180, 1) ## Frequency = 7 ## [1] 85 163 233 282 303 344 241 96 309 357 219 269 252 204 119 294 252 168 ## [19] 170 205 152 70 167 214 251 288 222 204 66 209 251 295 303 319 165 146 ## [37] 266 270 278 211 275 128 121 240 335 286 285 199 164 149 288 279 276 279 ## [55] 184 186 133 238 300 264 240 222 234 66 239 246 172 164 146 130 97 243 ## [73] 250 276 267 234 161 172 259 240 236 244 248 154 135 197 207 222 225 214 ## [91] 215 100 241 281 235 206 303 131 166 243 237 293 242 279 215 147 256 288 ## [109] 266 288 311 171 149 339 342 326 235 271 98 200 302 337 272 216 293 202 ## [127] 124 300 250 283 271 302 189 121 268 192 256 266 283 183 138 268 274 279 ## [145] 190 233 100 144 259 270 242 209 244 127 146 250 246 232 248 223 105 138 ## [163] 259 251 236 248 320 177 126 272 271 286 229 270 239 151 223 226 204 178 ## [181] 190 162 149 223 209 219 179 216 171 118 239 269 242 166 203 152 137 217 ## [199] 196 234 228 216 144 97 229 249 239 272 254 144 115 238 223 230 228 175 ## [217] 119 97 258 223 224 219 162 74 53 204 223 259 216 204 185 127 226 249 ## [235] 247 248 225 154 133 236 232 207 247 268 215 151 251 222 242 291 232 214 ## [253] 84 232 287 184 277 287 212 84 300 302 272 310 316 243 107 303 291 396 ## [271] 153 341 177 129 260 262 287 272 308 247 118 300 290 298 366 257 185 95 ## [289] 220 180 203 250 193 102 106 132 172 161 193 168 120 96 240 217 241 238 ## [307] 197 105 110 173 299 195 171 163 109 63 132 163 134 168 129 81 48 plot(tsData) require(RSNNS) ## Loading required package: RSNNS require(quantmod) ## Loading required package: quantmod ## Loading required package: xts ## Loading required package: zoo ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric ## Loading required package: TTR 4.6.1 Normalizar la Serie de tiempo Normalizar los datos es necesario para que tengan una escala similar. Esto puede ayudar a que la red neuronal converja más rápido y a obtener mejores resultados stsData&lt;-as.ts(tsData,F) stsDataN&lt;- (stsData-min(stsData))/(max(stsData)-min(stsData)) plot(stsDataN) 4.6.2 Definir Train Set y Test Set tamano_total &lt;- length(stsDataN) tamano_total ## [1] 323 tamano_train &lt;- round(tamano_total*0.75, digits = 0) train &lt;- 0:(tamano_train-1) train ## [1] 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ## [19] 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 ## [37] 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 ## [55] 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 ## [73] 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 ## [91] 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 ## [109] 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 ## [127] 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 ## [145] 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 ## [163] 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 ## [181] 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 ## [199] 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 ## [217] 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 ## [235] 234 235 236 237 238 239 240 241 test &lt;- (tamano_train):tamano_total test ## [1] 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 ## [20] 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 ## [39] 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 ## [58] 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 ## [77] 318 319 320 321 322 323 4.6.3 Creación de Secuencias El siguiente paso es convierte los datos de la serie de tiempo en secuencias. Esto implica dividir la serie de tiempo en segmentos más pequeños que se utilizarán como entradas y salidas de la red. En este caso como mi serie de tiempo es semanal, utilizare 7 lags. y &lt;- as.zoo(stsDataN) x1=lag(y,k=1) x2=lag(y,k=2) x3=lag(y,k=3) x4=lag(y,k=4) x5=lag(y,k=5) x6=lag(y,k=6) x7=lag(y,k=7) slogN &lt;- cbind(y,x1,x2,x3,x4,x5,x6,x7) 4.6.4 Diseño de la arquitectura de la red Se retiras las filas con nulos slogN &lt;- slogN[-(1:7),] De esta forma ya no presentamos nulos en la red Se definen los inputs y outputs, en este caso los 7 desfaces intentaran predecir la serie real inputs &lt;- slogN[,2:8] outputs &lt;- slogN[,1] 4.6.5 Entrenamiento de la red Se entrena el modelo con la red de entrenamiento set.seed(42) fit &lt;- fit&lt;-elman(inputs[train],outputs[train],size=c(7,3),learnFuncParams=c(0.1),maxit=64000) 4.6.6 Validación y ajuste de hiperparámetros En la grafica siguiente vemos como evoluciona el error de la red con el numero de iteraciones para los parmetros expuestos plotIterativeError(fit, main = &quot;Iterative Error for 7,3 Neuron&quot;) ### Evaluación del modelo y &lt;- as.vector(outputs[-test]) plot(y,type=&quot;l&quot;) pred &lt;- predict(fit, inputs[-test]) lines(pred,col = &quot;red&quot;) Como podemos ver en la grafica de Real Vs Predicor para el test set, las red neuronal de El 4.6.7 Modelo Red neuronal de Jordan En las redes Jordan, la diferencia esta en que la entrada de las neuronas de la capa de contexto se toma desde la salida de la red 4.6.8 Entrenamiento del modelo set.seed(42) fit &lt;-jordan(inputs[train],outputs[train],size=6,learnFuncParams=c(0.1),maxit=78000) plotIterativeError(fit, main = &quot;Iterative Error for 6 Neuron&quot;) y &lt;- as.vector(outputs[-test]) plot(y,type=&quot;l&quot;) pred &lt;- predict(fit, inputs[-test]) lines(pred,col = &quot;red&quot;) El ajuste en esta red neuronal tambien es muy bueno, sin embargo, el modelo de Elman muestra visualmente un mejor ajuste. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
